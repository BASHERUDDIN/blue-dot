<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Blue Dot AI</title>
<style>
body{
  margin:0;
  background:black;
  overflow:hidden;
}
canvas{
  position:absolute;
}
.controls{
  position:absolute;
  bottom:40px;
  width:100%;
  text-align:center;
}
button{
  padding:12px 25px;
  margin:5px;
  font-size:16px;
  border:none;
  border-radius:25px;
  background:#1e90ff;
  color:white;
}
</style>
</head>
<body>

<canvas id="canvas"></canvas>

<div class="controls">
  <button onclick="startMic()">Start Listening</button>
  <button onclick="stopMic()">Stop</button>
  <button onclick="simulateSpeak()">Simulate AI Speak</button>
</div>

<script>
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
canvas.width = window.innerWidth;
canvas.height = window.innerHeight;

let stream = null;
let audioContext = null;
let analyser = null;

let micAmplitude = 0;
let mouthAmplitude = 0;

let isListening = false;
let isSpeaking = false;

let ringRotation = 0;

// Eye movement
let pupilTargetX = 0;
let pupilTargetY = 0;
let pupilX = 0;
let pupilY = 0;

setInterval(()=>{
  if(!isListening && !isSpeaking){
    pupilTargetX = (Math.random()-0.5)*25;
    pupilTargetY = (Math.random()-0.5)*15;
  }
},2000);

async function startMic(){
  stream = await navigator.mediaDevices.getUserMedia({audio:true});
  audioContext = new AudioContext();
  const source = audioContext.createMediaStreamSource(stream);
  analyser = audioContext.createAnalyser();
  analyser.fftSize = 256;
  source.connect(analyser);
  isListening = true;
  updateMic();
}

function stopMic(){
  if(stream){
    stream.getTracks().forEach(track=>track.stop());
  }
  if(audioContext){
    audioContext.close();
  }
  isListening = false;
  isSpeaking = false;
  micAmplitude = 0;
  mouthAmplitude = 0;
}

function simulateSpeak(){
  isSpeaking = true;
  let duration = 2000;
  let start = Date.now();

  function animateSpeak(){
    let elapsed = Date.now() - start;
    mouthAmplitude = Math.sin(elapsed*0.02)*40;

    if(elapsed < duration){
      requestAnimationFrame(animateSpeak);
    } else {
      isSpeaking = false;
      mouthAmplitude = 0;
    }
  }
  animateSpeak();
}

function updateMic(){
  if(!analyser) return;

  const dataArray = new Uint8Array(analyser.frequencyBinCount);
  analyser.getByteTimeDomainData(dataArray);

  let sum = 0;
  for(let i=0;i<dataArray.length;i++){
    const v=(dataArray[i]-128)/128;
    sum+=v*v;
  }

  let raw = Math.sqrt(sum/dataArray.length)*600;

  micAmplitude = micAmplitude*0.7 + raw*0.3;

  requestAnimationFrame(updateMic);
}

function draw(){
  ctx.clearRect(0,0,canvas.width,canvas.height);

  const w = canvas.width;
  const h = canvas.height;

  const eyeY = h*0.35;
  const leftX = w*0.35;
  const rightX = w*0.65;

  // Smooth pupil movement
  pupilX += (pupilTargetX - pupilX)*0.08;
  pupilY += (pupilTargetY - pupilY)*0.08;

  // Eye color logic
  let eyeColor = "#4da6ff"; // blue

  if(isListening && micAmplitude > 20){
    eyeColor = "#9b59ff"; // purple when you talk
  }

  ctx.fillStyle = eyeColor;

  ctx.beginPath();
  ctx.arc(leftX,eyeY,65,0,Math.PI*2);
  ctx.fill();

  ctx.beginPath();
  ctx.arc(rightX,eyeY,65,0,Math.PI*2);
  ctx.fill();

  // Pupils
  ctx.fillStyle="#001933";
  ctx.beginPath();
  ctx.arc(leftX+pupilX,eyeY+pupilY,22,0,Math.PI*2);
  ctx.fill();

  ctx.beginPath();
  ctx.arc(rightX+pupilX,eyeY+pupilY,22,0,Math.PI*2);
  ctx.fill();

  // Rotating rings
  ctx.strokeStyle="#003366";
  ctx.lineWidth=6;
  ringRotation+=0.015;

  ctx.save();
  ctx.translate(leftX,eyeY);
  ctx.rotate(ringRotation);
  ctx.beginPath();
  ctx.arc(0,0,55,0,Math.PI*2);
  ctx.stroke();
  ctx.restore();

  ctx.save();
  ctx.translate(rightX,eyeY);
  ctx.rotate(ringRotation);
  ctx.beginPath();
  ctx.arc(0,0,55,0,Math.PI*2);
  ctx.stroke();
  ctx.restore();

  // Mouth ONLY when AI speaking
  const mouthY = h*0.65;
  ctx.lineWidth=12;

  ctx.beginPath();
  ctx.moveTo(w*0.45,mouthY - mouthAmplitude/2);
  ctx.lineTo(w*0.55,mouthY + mouthAmplitude/2);
  ctx.stroke();

  requestAnimationFrame(draw);
}

draw();
</script>

</body>
</html>  const eyeY=h*0.35;
  const leftX=w*0.35;
  const rightX=w*0.65;

  // Smooth pupil movement interpolation
  pupilX += (pupilTargetX - pupilX)*0.05;
  pupilY += (pupilTargetY - pupilY)*0.05;

  // Eyes
  ctx.fillStyle="#4da6ff";
  ctx.beginPath();
  ctx.arc(leftX,eyeY,65,0,Math.PI*2);
  ctx.fill();

  ctx.beginPath();
  ctx.arc(rightX,eyeY,65,0,Math.PI*2);
  ctx.fill();

  // Pupils
  ctx.fillStyle="#001933";
  ctx.beginPath();
  ctx.arc(leftX+pupilX,eyeY+pupilY,22,0,Math.PI*2);
  ctx.fill();

  ctx.beginPath();
  ctx.arc(rightX+pupilX,eyeY+pupilY,22,0,Math.PI*2);
  ctx.fill();

  // Rotating rings
  ctx.strokeStyle="#003366";
  ctx.lineWidth=6;
  ringRotation+=0.015;

  ctx.save();
  ctx.translate(leftX,eyeY);
  ctx.rotate(ringRotation);
  ctx.beginPath();
  ctx.arc(0,0,55,0,Math.PI*2);
  ctx.stroke();
  ctx.restore();

  ctx.save();
  ctx.translate(rightX,eyeY);
  ctx.rotate(ringRotation);
  ctx.beginPath();
  ctx.arc(0,0,55,0,Math.PI*2);
  ctx.stroke();
  ctx.restore();

  // Mouth vibration (clear but controlled)
  const mouthY=h*0.65;
  ctx.lineWidth=12;

  let tilt = listening ? amplitude : 0;

  ctx.beginPath();
  ctx.moveTo(w*0.45,mouthY - tilt/2);
  ctx.lineTo(w*0.55,mouthY + tilt/2);
  ctx.stroke();

  // Listening bars
  if(listening){
    ctx.fillStyle="#003366";
    ctx.fillRect(50,eyeY-50,14,110+amplitude/2);
    ctx.fillRect(w-64,eyeY-50,14,110+amplitude/2);
  }

  requestAnimationFrame(draw);
}

draw();
</script>

</body>
</html>
